<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Başak Güleçyüz</title>

    <meta name="author" content="Başak Güleçyüz">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0;border-spacing:0;border-collapse:separate;margin:auto;">
      <tbody>
        <tr>
          <td style="padding:0">

            <!-- ================= HEADER ================= -->
            <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:auto;">
              <tbody>
                <tr>
                  <td style="padding:2.5%;width:63%;vertical-align:middle">
                    <p class="name" style="text-align:center;">
                      Başak Güleçyüz
                    </p>


				
				<p>
I am a PhD candidate at the Chair of Media Technology, Munich Institute of Robotics and Machine Intelligence at the Technical University of Munich (TUM), supervised by Prof. Dr.-Ing. Eckehard Steinbach.

My research lies at the intersection of <strong>robotics</strong>, <strong>machine learning</strong>, and <strong>haptics</strong>, with a focus on teaching robots contact-rich <strong>manipulation</strong> skills through 
teleoperation.
 </p>

<p>
 In particular, I develop <strong>learning-from-demonstration</strong> and <strong>shared autonomy</strong> approaches that combine human input with learned autonomy to enable reliable physical interaction. A central theme of 
my work is addressing the challenges of remote skill transfer under real-world communication constraints, such as delay, packet loss, and limited bandwidth. More recently, I have been extending this work toward <strong>vision-guided imitation learning</strong>, with an interest in combining 
visual perception and interaction-aware learning for manipulation tasks.
</p>

				
                    <p style="text-align:center">
                      <a href="mailto:basak.gulecyuz@gmail.com">Email</a> &nbsp;/&nbsp;
                      <a href="https://linkedin.com/in/basakgulecyuz">Linkedin</a> &nbsp;/&nbsp;
                      <a href="https://scholar.google.com/citations?user=DGWMmtcAAAAJ">Scholar</a>
                    </p>
					
					

				
				
                  </td>

                  <td style="padding:2.5%;width:37%;max-width:37%">
                    <img style="width:100%;max-width:100%;object-fit:cover;border-radius:50%;"
                         src="images/profile.jpeg"
                         alt="Profile photo">
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- ================= RESEARCH ================= -->
            <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:auto;">
              <tbody>
                <tr>
                  <td style="padding:16px;width:100%;vertical-align:middle">
                  
					
					  <h2>Research & Selected Publications</h2>
			<table style="width:100%;border:0;border-spacing:0 10px;border-collapse:separate;margin:auto;">
					  <tbody>

						<tr>
						  <!-- Left: GIF -->
						  <td style="padding:16px;width:20%;vertical-align:middle">
							<img src="images/sa.png"
								 width="400"
								 style="border-radius:4px;"
								 alt="Shared autonomy">
						  </td>

						  <!-- Right: Text -->
						  <td style="padding:8px;width:80%;vertical-align:middle">
							<a href="https://ieeexplore.ieee.org/document/11115037" target="_blank" rel="noopener noreferrer">
							  <span class="papertitle">
								Enhancing Shared Autonomy in Teleoperation under Network Delay: Transparency- and Confidence-Aware Arbitration
							  </span>
							</a>
							<br>
							<strong>Başak Güleçyüz</strong>,
							Ribin Balachandran,
							Michael Panzirsch,
							Harsimran Singh,
							Thomas Hulin,
							Xiao Xu,
							Eckehard Steinbach
							<br>
							<em>IEEE Robotics and Automation Letters (RA-L)</em>, 2025
							<br>

							<p></p>
							<p>
							  We propose a shared autonomy approach for teleoperation under network delay that combines delay-aware intent inference, confidence-based arbitration, 
							  and passivity-preserving control to improve task performance and learning quality.
							</p>
						  </td>
						</tr>

					  </tbody>
					</table>

 <!-- ================= SELECTED PUBLICATION ================= -->
					<table style="width:100%;border:0;border-spacing:0 10px;border-collapse:separate;margin:auto;">
					  <tbody>

						<tr>
						  <!-- Left: GIF -->
						  <td style="padding:16px;width:20%;vertical-align:middle">
							<img src="images/netlfd_gif_new.gif"
								 width="400"
								 style="border-radius:4px;"
								 alt="NetLfD demonstration GIF">
						  </td>

						  <!-- Right: Text -->
						  <td style="padding:8px;width:80%;vertical-align:middle">
							<a href="https://ieeexplore.ieee.org/abstract/document/10244098" target="_blank" rel="noopener noreferrer">
							  <span class="papertitle">
								Netlfd: Network-aware learning from demonstration for in-contact skills via teleoperation
							  </span>
							</a>
							<br>
							<strong>Başak Güleçyüz</strong>,
							Vincent von Büren,
							Xiao Xu,
							Eckehard Steinbach
							<br>
							<em>IEEE Robotics and Automation Letters (RA-L)</em>, 2023
							<br>

							<p></p>
							<p>
							  We propose a network-aware learning-from-demonstration framework that
							  explicitly accounts for delay and packet loss during teleoperation,
							  enabling reliable learning of contact-rich manipulation skills from
							  degraded demonstrations.
							</p>
						  </td>
						</tr>

					  </tbody>
					</table>
					
					
					 <!-- ================= SELECTED PUBLICATION ================= -->
					<table style="width:100%;border:0;border-spacing:0 10px;border-collapse:separate;margin:auto;">
					  <tbody>

						<tr>
						  <!-- Left: GIF -->
						  <td style="padding:16px;width:20%;vertical-align:middle">
							<img src="images/overview_lac.png"
								 width="400"
								 style="border-radius:4px;"
								 alt="LAC">
						  </td>

						  <!-- Right: Text -->
						  <td style="padding:8px;width:80%;vertical-align:middle">
							<a href="https://ieeexplore.ieee.org/document/9562240" target="_blank" rel="noopener noreferrer">
							  <span class="papertitle">
								Learning-Adaptive Deadband Sampling for Teleoperation-based Skill Transfer over the Tactile Internet
							  </span>
							</a>
							<br>
							<strong>Başak Güleçyüz</strong>,
							Luca Oppici,
							Xiao Xu,
							Andreas Noll
							Eckehard Steinbach
							<br>
							<em>IEEE ISWCS</em>, 2021
							<br>

							<p></p>
							<p>
							We propose a learning-adaptive perceptual deadband-based sapling approach that adjusts haptic
							data transmission based on learning progress, reducing
							communication load while preserving the quality of learned manipulation skills.
							</p>
						  </td>
						</tr>

					  </tbody>
					</table>
					
					
					 <!-- ================= SELECTED PUBLICATION ================= -->
					<table style="width:100%;border:0;border-spacing:0 10px;border-collapse:separate;margin:auto;">
					  <tbody>

						<tr>
						  <!-- Left: GIF -->
						  <td style="padding:16px;width:20%;vertical-align:middle">
							<img src="images/pvc_slp.png"
								 width="400"
								 style="border-radius:4px;"
								 alt="PVC_SLP">
						  </td>

						  <!-- Right: Text -->
						  <td style="padding:8px;width:80%;vertical-align:middle">
							<a href="https://ieeexplore.ieee.org/document/9281368" 
							target="_blank" rel="noopener noreferrer">
							  <span class="papertitle">
								PVC-SLP: Perceptual Vibrotactile-Signal Compression Based-on Sparse Linear Prediction
							  </span>
							</a>
							<br>
							Rania HAssen,
							<strong>Başak Güleçyüz</strong>,
							Eckehard Steinbach
							<br>
							<em>IEEE Transactions on Multimedia</em>, 2020
							<br>

							<p></p>
							<p>
							We propose PVC-SLP, a perceptual vibrotactile compression method that leverages tactile sensitivity modeling and 
							sparse linear prediction to efficiently encode vibrotactile signals while maintaining high perceptual fidelity.
							</p>
						  </td>
						</tr>

					  </tbody>
					</table>
					
					
					

                  </td>
                </tr>
              </tbody>
            </table>



          </td>
        </tr>
      </tbody>
    </table>
  </body>
</html>
